{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings and Dense Vector Search: A Quick Primer\n",
    "\n",
    "If you come from an NLP background, embeddings are something you might be intimately familiar with - otherwise, you might find the topic a bit...dense. (this attempt at a joke will make more sense later)\n",
    "\n",
    "In all seriousness, embeddings are a powerful piece of the NLP puzzle, so let's dive in!\n",
    "\n",
    "> NOTE: While this notebook is language/NLP-centric, embeddings have uses beyond just text!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why Do We Even Need Embeddings?\n",
    "\n",
    "In order to fully understand what Embeddings are, we first need to understand why we have them!\n",
    "\n",
    "Machine Learning algorithms, ranging from the very big to the very small, all have one thing in common:\n",
    "\n",
    "They need numeric inputs.\n",
    "\n",
    "So we need a process by which to translate the domain we live in, dominated by images, audio, language, and more, into the domain of the machine: Numbers.\n",
    "\n",
    "Another thing we want to be able to do is capture \"semantic information\" about words/phrases so that we can use algorithmic approaches to determine if words are closely related or not!\n",
    "\n",
    "So, we need to come up with a process that does these two things well:\n",
    "\n",
    "- Convert non-numeric data into numeric-data\n",
    "- Capture potential semantic relationships between individual pieces of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Do Embeddings Capture Semantic Relationships?\n",
    "\n",
    "In a simplified sense, embeddings map a word or phrase into n-dimensional space with a dense continuous vector, where each dimension in the vector represents some \"latent feature\" of the data.\n",
    "\n",
    "This is best represented in a classic example:\n",
    "\n",
    "![image](https://i.imgur.com/K5eQtmH.png)\n",
    "\n",
    "As can be seen in the extremely simplified example: The X_1 axis represents age, and the X_2 axis represents hair.\n",
    "\n",
    "The relationship of \"puppy -> dog\" reflects the same relationship as \"baby -> adult\", but dogs are (typically) hairier than humans. However, adults typically have more hair than babies - so they are shifted slightly closer to dogs on the X_2 axis!\n",
    "\n",
    "Now, this is a simplified and contrived example - but it is *essentially* the mechanism by which embeddings capture semantic information.\n",
    "\n",
    "In reality, the dimensions don't sincerely represent hard-concepts like \"age\" or \"hair\", but it's useful as a way to think about how the semantic relationships are captured.\n",
    "\n",
    "Alright, with some history behind us - let's examine how these might help us choose relevant context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin with a simple example - simply looking at how close two embedding vectors are for a given phrase.\n",
    "\n",
    "When we use the term \"close\" in this notebook - we're referring to a distance measure called \"cosine similarity\".\n",
    "\n",
    "We discussed above that if two embeddings are close - they are semantically similar, cosine similarity gives us a quick way to measure how similar two vectors are!\n",
    "\n",
    "Closeness is measured from 1 to -1, with 1 being extremely close and -1 being extremely close to opposite in meaning.\n",
    "\n",
    "Let's implement it with Numpy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def cosine_similarity(vec_1, vec_2):\n",
    "  return np.dot(vec_1, vec_2) / (norm(vec_1) * norm(vec_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the `all-MiniLM-L6-v2` embedding model from [sentence-transformers](https://www.sbert.net/) to embed two sentences. This is a lightweight model that runs locally - no API key needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36cac6598384301b9af7e3acc56d7f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c62d177295401090395af433e34f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653527f36c2e4811a8c699c40f7f755c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10e16973f084887bea3f0b53c1b5e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499548db2dad40be94215657a4580d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7794974e893a4fd4b227ba0fd41e16f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47f36415778489ab3dee75a6fe9d125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19d4c7ed5d7490188aa5d09afeca72e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f55258207a847e28e30412ad2776cb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc24ddb3225a4fd28990a3a5bcb09ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e184a1347f4a1380c3887172cb7fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b218106f99431f8128ceb5b8a43220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pretrained Sentence Transformer model (runs locally)\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our two sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "puppy_sentence = \"i love puppies\"\n",
    "dog_sentence = \"i love dogs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can convert those into embedding vectors using our local model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "puppy_vector = model.encode(puppy_sentence)\n",
    "dog_vector = model.encode(dog_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can determine how closely they are related using our distance measure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.7885634)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(puppy_vector, dog_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, with cosine similarity, close to 1. means they're very close!\n",
    "\n",
    "Let's see what happens if we use a different set of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.50499433)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "puppy_sentence = \"I love puppies!\"\n",
    "cat_sentence = \"I dislike cats!\"\n",
    "\n",
    "puppy_vector = model.encode(puppy_sentence)\n",
    "cat_vector = model.encode(cat_sentence)\n",
    "\n",
    "cosine_similarity(puppy_vector, cat_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - these vectors are further apart - as expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Vector Calculations\n",
    "\n",
    "One of the ways that Embedding Vectors can be leveraged, and a fun \"proof\" that they work the way we expected can be explored via \"Vector Calculations\"\n",
    "\n",
    "That is to say: If we take the vector for \"King\", and subtract the vector for \"man\", and add the vector for \"woman\" - we should have a vector that is similar to \"Queen\".\n",
    "\n",
    "Let's try this out below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.5794788)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king_vector = model.encode(\"King\")\n",
    "man_vector = model.encode(\"man\")\n",
    "woman_vector = model.encode(\"woman\")\n",
    "\n",
    "vector_calculation_result = king_vector - man_vector + woman_vector\n",
    "\n",
    "queen_vector = model.encode(\"Queen\")\n",
    "\n",
    "cosine_similarity(vector_calculation_result, queen_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see - the resulting vector is indeed quite close to the \"Queen\" vector!\n",
    "\n",
    "> NOTE: The loss is explained by the vectors not *literally* encoding information along axes as simple as \"man\" or \"woman\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As you can see - embeddings can help us convert text into a machine understandable format, which we can leverage for a number of purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
